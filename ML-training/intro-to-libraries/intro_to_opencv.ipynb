{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFKi0ywwCu5UsHW7KF7icm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniel-falk/ai-ml-principles-exercises/blob/main/ML-training/intro-to-libraries/intro_to_opencv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenCV is a python library for images\n",
        "OpenCV can be used for:\n",
        "* Drawing on images\n",
        "* Performing common transformations\n",
        "* Analyzing images\n",
        "* Reading and writing images and video\n",
        "* Converting between color spaces\n",
        "\n",
        "The library and project is called `OpenCV` but the python package is named `cv2`."
      ],
      "metadata": {
        "id": "F-cvfwvKQDq_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-K86PpqNbcn"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/8/8a/Automation_of_foundry_with_robot.jpg\n",
        "bgr_img = cv2.imread(\"Automation_of_foundry_with_robot.jpg\")"
      ],
      "metadata": {
        "id": "cXcRVeqfNfGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Image type: \", type(bgr_img))\n",
        "print(\"Image shape: \", bgr_img.shape)"
      ],
      "metadata": {
        "id": "tBIsAowLPxC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.fromarray(bgr_img)"
      ],
      "metadata": {
        "id": "TRW6vnGWNiLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
        "Image.fromarray(rgb_img)"
      ],
      "metadata": {
        "id": "ZFt3GcJUPMCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.fromarray(cv2.resize(rgb_img, (50, 50)))"
      ],
      "metadata": {
        "id": "nd6MKK-TPqYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drawing\n",
        "OpenCV can be used to draw text and shapes on images."
      ],
      "metadata": {
        "id": "FAXxIMs1Q7jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_draw = rgb_img.copy()\n",
        "cv2.rectangle(rgb_draw, (150,50), (370,390), color=(255,0,0), thickness=3)\n",
        "Image.fromarray(rgb_draw)"
      ],
      "metadata": {
        "id": "JIJt5T-xQ0sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_draw = rgb_img.copy()\n",
        "cv2.circle(rgb_draw, center=(175,240), radius=50, color=(0,255,0), thickness=3)\n",
        "Image.fromarray(rgb_draw)"
      ],
      "metadata": {
        "id": "sr6_xUW7Ri1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_draw = rgb_img.copy()\n",
        "cv2.putText(rgb_draw, \"Image 0\", org=(50, 50), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=3, color=(255,0,0))\n",
        "Image.fromarray(rgb_draw)"
      ],
      "metadata": {
        "id": "JW7NypnQSXZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transforming images\n",
        "Images can be transformed in various ways using the library."
      ],
      "metadata": {
        "id": "NubyQHcETlsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h, w = rgb_img.shape[:2]\n",
        "center = (w//2,h//2)\n",
        "  \n",
        "# Generating a rotation matrix\n",
        "angle = 45.\n",
        "scale = 1.\n",
        "rot_matrix = cv2.getRotationMatrix2D(center, angle, scale) \n",
        "  \n",
        "# Performing the affine transformation\n",
        "# Note that this is not an inplace operation since destination size\n",
        "# might be different from the source size to not loose the corners of the image\n",
        "rot_rgb = cv2.warpAffine(rgb_img, rot_matrix, dsize=(w, h))\n",
        "Image.fromarray(rot_rgb)"
      ],
      "metadata": {
        "id": "M0CGgGq7S8Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur_rgb = cv2.GaussianBlur(rgb_img, ksize=(21, 21), sigmaX=9)\n",
        "Image.fromarray(blur_rgb)"
      ],
      "metadata": {
        "id": "XM_i8nXxUZFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges_rgb = cv2.Canny(image=rgb_img, threshold1=100, threshold2=200)\n",
        "Image.fromarray(edges_rgb)"
      ],
      "metadata": {
        "id": "OVHRvtcGVHdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)\n",
        "blur_rgb = cv2.GaussianBlur(gray_img, ksize=(11, 11), sigmaX=2)\n",
        "edges_rgb = cv2.Canny(image=blur_rgb, threshold1=20, threshold2=100)\n",
        "Image.fromarray(edges_rgb)"
      ],
      "metadata": {
        "id": "mDzKIrbFVpBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Object detection and matching\n",
        "OpenCV does also have more complex algorithms such as face detectors and feature point matching."
      ],
      "metadata": {
        "id": "n7cBNgLNW9dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://upload.wikimedia.org/wikipedia/commons/2/2e/Al_Hurricane_and_Al_Hurricane%2C_Jr._performing_at_the_San_Felipe_De_Neri_2014_fiestas.jpg\" -O img.jpg\n",
        "concert_img = cv2.cvtColor(cv2.imread(\"img.jpg\"), cv2.COLOR_BGR2RGB)\n",
        "h, w = concert_img.shape[:2]\n",
        "concert_img = cv2.resize(concert_img, (w//4, h//4))\n",
        "Image.fromarray(concert_img)"
      ],
      "metadata": {
        "id": "2vmQgwAEXG7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a pretrained cascade definition for the detector\n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
        "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
      ],
      "metadata": {
        "id": "J_EPuvfwZNvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concert_gray = cv2.cvtColor(concert_img, cv2.COLOR_RGB2GRAY)\n",
        "faces = face_detector.detectMultiScale(concert_gray,  scaleFactor=1.1, minNeighbors=1)\n",
        "\n",
        "# Draw the rectangle around each face\n",
        "print(f\"Found {len(faces)} faces\")\n",
        "draw_rgb = concert_img.copy()\n",
        "for (x, y, w, h) in faces:\n",
        "  cv2.rectangle(draw_rgb, (x, y), (x+w, y+h), color=(255, 0, 0), thickness=2)\n",
        "Image.fromarray(draw_rgb)"
      ],
      "metadata": {
        "id": "Ef70woi5XYDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature point matching\n",
        "Finding and matching features can be used to locate the same objects in similar images, or as in this example overlapping crops of the same image."
      ],
      "metadata": {
        "id": "oPKWDOQ-apzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "h, w = concert_img.shape[:2]\n",
        "img1 = concert_img[:,:w//2 + 50]\n",
        "img2 = concert_img[:,w//2 - 50:]\n",
        "display(Image.fromarray(img1), Image.fromarray(img2))"
      ],
      "metadata": {
        "id": "csCUpY6_a06y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find features in the two images\n",
        "feature = cv2.ORB_create(nfeatures=5000)\n",
        "keypoints1, descriptors1 = feature.detectAndCompute(img1, None)\n",
        "keypoints2, descriptors2 = feature.detectAndCompute(img2, None)\n",
        "\n",
        "# match the features across the two images\n",
        "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "matches = matcher.match(descriptors1, descriptors2)\n",
        "matches = sorted(matches, key=lambda x: x.distance)  # Sort most similar first\n",
        "\n",
        "# draw first 50 matches\n",
        "match_img = cv2.drawMatches(\n",
        "    img1, keypoints1, img2, keypoints2,\n",
        "    matches[:50], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
        ")\n",
        "Image.fromarray(match_img)"
      ],
      "metadata": {
        "id": "EnuY7koubGLS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}